{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q10-i0H_bCW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest R^2 Score: -0.6965 (Accuracy: -69.65%)\n",
      "GradientBoosting R^2 Score: -1.1079 (Accuracy: -110.79%)\n",
      "AdaBoost R^2 Score: -1.0175 (Accuracy: -101.75%)\n",
      "ExtraTrees R^2 Score: -0.7134 (Accuracy: -71.34%)\n",
      "DecisionTree R^2 Score: -0.8214 (Accuracy: -82.14%)\n",
      "XGBoost R^2 Score: -0.5332 (Accuracy: -53.32%)\n",
      "RandomForest R^2 Score: -0.6843 (Accuracy: -68.43%)\n",
      "GradientBoosting R^2 Score: -0.3960 (Accuracy: -39.60%)\n",
      "AdaBoost R^2 Score: -0.7068 (Accuracy: -70.68%)\n",
      "ExtraTrees R^2 Score: -0.9191 (Accuracy: -91.91%)\n",
      "DecisionTree R^2 Score: -1.8511 (Accuracy: -185.11%)\n",
      "XGBoost R^2 Score: -1.6595 (Accuracy: -165.95%)\n",
      "RandomForest R^2 Score: -0.5429 (Accuracy: -54.29%)\n",
      "GradientBoosting R^2 Score: -1.6423 (Accuracy: -164.23%)\n",
      "AdaBoost R^2 Score: -0.2359 (Accuracy: -23.59%)\n",
      "ExtraTrees R^2 Score: -1.8439 (Accuracy: -184.39%)\n",
      "DecisionTree R^2 Score: -1.1542 (Accuracy: -115.42%)\n",
      "XGBoost R^2 Score: -1.0847 (Accuracy: -108.47%)\n",
      "Best models saved successfully.\n",
      "\n",
      "Accuracy of models for Article A:\n",
      "RandomForest: -69.65%\n",
      "GradientBoosting: -110.79%\n",
      "AdaBoost: -101.75%\n",
      "ExtraTrees: -71.34%\n",
      "DecisionTree: -82.14%\n",
      "XGBoost: -53.32%\n",
      "\n",
      "Accuracy of models for Article B:\n",
      "RandomForest: -68.43%\n",
      "GradientBoosting: -39.60%\n",
      "AdaBoost: -70.68%\n",
      "ExtraTrees: -91.91%\n",
      "DecisionTree: -185.11%\n",
      "XGBoost: -165.95%\n",
      "\n",
      "Accuracy of models for Article C:\n",
      "RandomForest: -54.29%\n",
      "GradientBoosting: -164.23%\n",
      "AdaBoost: -23.59%\n",
      "ExtraTrees: -184.39%\n",
      "DecisionTree: -115.42%\n",
      "XGBoost: -108.47%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "data_articles = pd.read_csv('forarticles.csv')\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform 'Day' column with OneHotEncoder\n",
    "day_encoded = encoder.fit_transform(data_articles[['Day']])\n",
    "\n",
    "# Convert the array back to a DataFrame\n",
    "day_encoded_df = pd.DataFrame(day_encoded.toarray(), columns=encoder.get_feature_names_out(['Day']))\n",
    "\n",
    "# Features for all articles\n",
    "X = pd.concat([day_encoded_df, data_articles[['Customer Count']]], axis=1)\n",
    "\n",
    "# Targets for each article, directly using the count\n",
    "y_A = data_articles['ArticleA']\n",
    "y_B = data_articles['ArticleB']\n",
    "y_C = data_articles['ArticleC']\n",
    "\n",
    "# Splitting the data into training and testing sets for each article\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X, y_A, test_size=0.2, random_state=42)\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X, y_B, test_size=0.2, random_state=42)\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X, y_C, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models to evaluate\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'ExtraTrees': ExtraTreesRegressor(random_state=42),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models and return the best model based on R^2 score\n",
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    best_model = None\n",
    "    best_r2_score = float('-inf')\n",
    "    model_accuracies = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        accuracy_percentage = r2 * 100\n",
    "        model_accuracies[name] = accuracy_percentage\n",
    "        print(f\"{name} R^2 Score: {r2:.4f} (Accuracy: {accuracy_percentage:.2f}%)\")\n",
    "        if r2 > best_r2_score:\n",
    "            best_r2_score = r2\n",
    "            best_model = model\n",
    "    return best_model, best_r2_score, model_accuracies\n",
    "\n",
    "# Evaluate and select the best model for each target\n",
    "best_model_A, best_r2_A, accuracies_A = evaluate_models(X_train_A, X_test_A, y_train_A, y_test_A)\n",
    "best_model_B, best_r2_B, accuracies_B = evaluate_models(X_train_B, X_test_B, y_train_B, y_test_B)\n",
    "best_model_C, best_r2_C, accuracies_C = evaluate_models(X_train_C, X_test_C, y_train_C, y_test_C)\n",
    "\n",
    "# Save the best models and the encoder\n",
    "pickle.dump(best_model_A, open('best_model_a.pkl', 'wb'))\n",
    "pickle.dump(best_model_B, open('best_model_b.pkl', 'wb'))\n",
    "pickle.dump(best_model_C, open('best_model_c.pkl', 'wb'))\n",
    "pickle.dump(encoder, open('encoder.pkl', 'wb'))\n",
    "\n",
    "print(\"Best models saved successfully.\")\n",
    "\n",
    "# Print the accuracy percentage for each model\n",
    "print(\"\\nAccuracy of models for Article A:\")\n",
    "for name, accuracy in accuracies_A.items():\n",
    "    print(f\"{name}: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nAccuracy of models for Article B:\")\n",
    "for name, accuracy in accuracies_B.items():\n",
    "    print(f\"{name}: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nAccuracy of models for Article C:\")\n",
    "for name, accuracy in accuracies_C.items():\n",
    "    print(f\"{name}: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "xQwxZ5BU0ljC",
    "outputId": "ec857374-f48e-4412-e960-7eb5019a0102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model Parameters:\")\n",
    "print(best_model_A.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RkGHTAdmL7i",
    "outputId": "32197434-7645-4942-9a3a-2783c6ce0e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Article A: [51.463856]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open('best_model_a.pkl', 'rb') as f:\n",
    "    model_a = pickle.load(f)\n",
    "\n",
    "# Manually create a DataFrame with the features\n",
    "# Let's assume we are predicting for Monday with 100 customers\n",
    "# We need to set the correct flags for one-hot encoded days\n",
    "data = {\n",
    "    'Day_Friday': [1],\n",
    "    'Day_Monday': [0],\n",
    "    'Day_Saturday': [0],\n",
    "    'Day_Sunday': [0],\n",
    "    'Day_Thursday': [0],\n",
    "    'Day_Tuesday': [0],\n",
    "    'Day_Wednesday': [0],\n",
    "    'Customer Count': [100]\n",
    "}\n",
    "\n",
    "features_df = pd.DataFrame(data)\n",
    "\n",
    "# Now use the model to predict\n",
    "prediction = model_a.predict(features_df)\n",
    "print(\"Prediction for Article A:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
